# Author: Akira Kudo
# Created: 2024/03/19
# Last Updated: 2024/06/20

import os
from typing import List

from feature_extraction.extract_label_and_feature_from_csv import create_labeled_feature_csv_from_label_and_feature_array, extract_label_and_feature_from_csv, LABELED_FEATURE_CSV_SUFFIX
from feature_extraction.extract_pregenerated_labels_and_compute_features import extract_pregenerated_labels_and_compute_features

POSE = list(range(3*6)) # <- 3 (x,y,lhl) columns x 6 body parts
# 6 bodyparts: snout, rightfrontpaw, leftfrontpaw, righthindpaw, lefthindpaw, tailbase; [belly]

def do_feature_extraction(csv_path : str,
                          predictions_path : str,
                          clf_sav_path : str,
                          computed_feature_saving_path : str,
                          feature_loading_path : str,
                          fps : int=40,
                          brute_thresholding : bool=False, 
                          threshold : float=0.8,
                          recompute : bool=False,
                          save_result : bool=True,
                          pose : List[int]=POSE
                          ):
    """
    Execute feature extraction on a csv, returning the obtained labels & csvs.

    :param str csv_path: A dlc csv holding body part movement data.
    :param str predictions_path: Path to predictions file generated by
    a B-SOID network.
    :param str clf_sav_path: Path to a B-SOID random forest classifier
    we use to extract features. 
    :param str computed_feature_saving_path: Path to where we save the 
    computed features & labels & csv. 
    :param str feature_loading_path: Path from where we load precomputed 
    features and labels.
    :param int fps: Frame per second used to record the csv_path file, default=40.
    :param bool brute_thresholding: Whether to use brute thresholding when filtering for
    extracted B-SOID features. Only guaranteed if recompute is True, and defauls to false.
    :param float threshold: Threshold when brute thresholding is done. Only guaranteed 
    if recompute is True, and defaults to 0.8.
    :param bool recompute: Whether to recompute if prior results are found, default=False.
    :param bool save_result: Whether to save computation results, default=True.
    :param List[int] pose: List of column index to extract from dlc csv. Often extract
    num_bodypart x 3 (x,y,likelihood) values . Defaults to POSE, every body part but belly.

    :returns np.ndarray labels: Extracted labels.
    :returns np.ndarray features: Extracted features.
    """
    labels, features = None, None
    if not recompute:
        print("Attempting fetch of previous results, brute_thresholding and threshold " + 
              "aren't guaranteed to have meaning.")

    if predictions_path is not None and not recompute:
        print("Extracting pregenerated labels and computing features!")
        labels, features = extract_pregenerated_labels_and_compute_features(
            predictions_path, os.path.basename(csv_path), 
            clf_sav_path=clf_sav_path, fps=fps,
            save_result=save_result, save_path=computed_feature_saving_path,
            recompute=recompute,  load_path=feature_loading_path
            )
        print("End.")

    if labels is None or features is None:
        print("Extraction of pregenerated labels somehow failed...")
        print("Computing both labels and features from csv!")
        labels, features = extract_label_and_feature_from_csv(
            filepath=csv_path, pose=pose, clf_path=clf_sav_path, fps=fps,
            brute_thresholding=brute_thresholding, threshold=threshold, 
            save_result=save_result, save_path=computed_feature_saving_path,
            recompute=recompute, load_path=feature_loading_path)
        print("End.")
    
    return labels, features

def do_feature_extraction_from_multiple_folders(
        csv_holding_folders : List[str],
        predictions_path : str,
        clf_sav_path : str,
        computed_feature_saving_path : str,
        feature_loading_path : str,
        fps : int=40,
        brute_thresholding : bool=False, 
        threshold : float=0.8,                  
        recompute : bool=False,
        save_result : bool=True,
        pose : List[int]=POSE
        ):
    """
    Execute feature extraction on a set csvs, all contained in of folders & csvs.

    :param list csv_holding_folders: A list of paths to csv-holding
    directories.
    :param str predictions_path: Path to predictions file generated by
    a B-SOID network.
    :param str clf_sav_path: Path to a B-SOID random forest classifier
    we use to extract features. 
    :param str computed_feature_saving_path: Path to where we save the 
    computed features & labels & csv. 
    :param str feature_loading_path: Path from where we load precomputed 
    features and labels.
    :param int fps: Frame per second used to record the csv_path file, default=40.
    :param bool brute_thresholding: Whether to use brute thresholding when filtering for
    extracted B-SOID features. Only guaranteed if recompute is True, and defauls to false.
    :param float threshold: Threshold when brute thresholding is done. Only guaranteed 
    if recompute is True, and defaults to 0.8.
    :param bool recompute: Whether to recompute if prior results are found, default=False.
    :param bool save_result: Whether to save computation results, default=True.
    :param List[int] pose: List of column index to extract from dlc csv. Often extract
    num_bodypart x 3 (x,y,likelihood) values . Defaults to POSE, every body part but belly.

    :returns List[Tuple[np.ndarray, np.ndarray]] label_N_features: The labels & features 
    extracted from the folders, as tuples: (labels, features), and in order of extraction.
    """
    label_N_features = []

    for csv_holding_fldr in csv_holding_folders:
        print(f"Processing folder: {os.path.basename(csv_holding_fldr)}!")
        
        for filepath in os.listdir(csv_holding_fldr):
            if not filepath.endswith('.csv'): continue
            print(f"- {filepath} ... ")
            csvpath = os.path.join(csv_holding_fldr, filepath)
        
            label, feature = do_feature_extraction(csv_path=csvpath, 
                                                    predictions_path=predictions_path,
                                                    clf_sav_path=clf_sav_path, 
                                                    computed_feature_saving_path=computed_feature_saving_path, 
                                                    feature_loading_path=feature_loading_path,
                                                    fps=fps,
                                                    brute_thresholding=brute_thresholding,
                                                    threshold=threshold,
                                                    recompute=recompute, 
                                                    save_result=save_result,
                                                    pose=pose)
            
            label_N_features.append((label, feature))

    return label_N_features

def extract_labeled_csv_through_walk(
        root : str,
        target : str,
        predictions_path : str,
        clf_sav_path : str,
        computed_feature_saving_path : str,
        feature_loading_path : str,
        fps : int=40,
        brute_thresholding : bool=False, 
        threshold : float=0.8,       
        recompute : bool=False,
        save_result : bool=True,
        pose : List[int]=POSE
        ):
    """
    Given a root directory, walks through its subdirectories, copying the 
    same directory structure to 'target'. When encoutering a csv: 
     - execute feature extraction on it, checking 'feature_loading_path'
     - save the computed feature & labels to 'computed_feature_saving_path' 
     - create the labeled csv and save it within the corresponding directory
       it was found, but in 'target'.

    :param str root: Path to root directory containing all DLC csvs somewhere deeper.
    :param str target: Path to target directory to which we copy the directory structure.
    :param str predictions_path: Path to predictions file generated by
    a B-SOID network.
    :param str clf_sav_path: Path to a B-SOID random forest classifier
    we use to extract features. 
    :param str computed_feature_saving_path: Path to where we save the 
    computed features & labels & csv. 
    :param str feature_loading_path: Path from where we load precomputed 
    features and labels.
    :param int fps: Frame per second used to record the csv_path file, default=40.
    :param bool brute_thresholding: Whether to use brute thresholding when filtering for
    extracted B-SOID features. Only guaranteed if recompute is True, and defauls to false.
    :param float threshold: Threshold when brute thresholding is done. Only guaranteed 
    if recompute is True, and defaults to 0.8.
    :param bool recompute: Whether to recompute if prior results are found, default=False.
    :param bool save_result: Whether to save computation results, default=True.
    :param List[int] pose: List of column index to extract from dlc csv. Often extract
    num_bodypart x 3 (x,y,likelihood) values . Defaults to POSE, every body part but belly.
    """
    def convert_relative_to_target(path : str):
        """
        Given a path under 'root', convert it to point its corresponding
        position among the tree rooted at 'target'.
        """
        conv_path = path.replace(os.path.split(root)[0], target)
        return conv_path

    # first check target exist
    if not os.path.exists(target): 
        raise Exception(f"Target seems to be non-existent: {target}")

    for dirpath, _, filenames in os.walk(root):
        # copy this directory under target first
        conv_path = convert_relative_to_target(dirpath)
        if not os.path.exists(conv_path):
            os.mkdir(conv_path)

        # then execute feature extraction for all csvs in this directory
        csvfiles = [file for file in filenames if file.endswith('.csv')]
        if len(csvfiles) != 0:
            print(f"Processing folder: {os.path.basename(dirpath)}!")
        
        for filename in csvfiles:
            print(f"- {filename} ... ")
            csvpath = os.path.join(dirpath, filename)
            # run feature extraction to get the label & feature
            label, feature = do_feature_extraction(csv_path=csvpath, 
                                                    predictions_path=predictions_path,
                                                    clf_sav_path=clf_sav_path, 
                                                    computed_feature_saving_path=computed_feature_saving_path, 
                                                    feature_loading_path=feature_loading_path,
                                                    fps=fps,
                                                    brute_thresholding=brute_thresholding,
                                                    threshold=threshold,
                                                    recompute=recompute, 
                                                    save_result=save_result,
                                                    pose=pose)
            # then resave the labeled feature csv into a given position
            clfname = os.path.basename(clf_sav_path).replace('_randomforest.sav', '')
            lbld_feats_filename = f"{clfname}_{filename.replace('.csv','')}{LABELED_FEATURE_CSV_SUFFIX}"
            create_labeled_feature_csv_from_label_and_feature_array(
                label=label,
                feature=feature,
                save_path=conv_path,
                pose=pose,
                lbld_feats_filename=lbld_feats_filename
                )
        
if __name__ == "__main__":
    def convert_to_current_file_drive(path : str):
        """
        Converts a given path so that its drive points to the same one
        as the drive this file is contained in.
        Used because it's annoying that between my laptop and NINC computers,
        the NINC drive is mounted with different names.
        """
        if path is None: return None
        current_drive, _ = os.path.splitdrive(os.path.abspath(__file__))
        _, remaining_path = os.path.splitdrive(path)
        return os.path.join(current_drive, remaining_path)

    # CLFPATH = r"Z:\Raymond Lab\2 Colour D1 D2 Photometry Project\Akira\BSOID\YAC128\Feb232023\output\Feb-23-2023_randomforest.sav"
    CLFPATH = r"X:\Raymond Lab\2 Colour D1 D2 Photometry Project\Akira\BSOID\Q175\Apr082024\output\Apr-08-2024_randomforest.sav"

    SAVEPATH = r"X:\Raymond Lab\2 Colour D1 D2 Photometry Project\Akira\BSOID\results\feats_labels"

    LOADPATH = r"X:\Raymond Lab\2 Colour D1 D2 Photometry Project\Akira\BSOID\results\feats_labels"

    PREDICTIONS_PATH = None #r"Z:\Raymond Lab\2 Colour D1 D2 Photometry Project\Akira\BSOID_data\Q175\Apr082024\output"

    # if running on a bunch of csvs in the given folder
    CSV_HOLDING_FOLDERS = [
        r"Z:\Raymond Lab\2 Colour D1 D2 Photometry Project\Akira\DLC\Q175\csv\found_by_script_csvs\it6-2500k"
    ]

    
    # convert everything to the right file drive
    CLFPATH = convert_to_current_file_drive(CLFPATH)
    SAVEPATH = convert_to_current_file_drive(SAVEPATH)
    LOADPATH = convert_to_current_file_drive(LOADPATH)
    PREDICTIONS_PATH = convert_to_current_file_drive(PREDICTIONS_PATH)
    CSV_HOLDING_FOLDERS = [convert_to_current_file_drive(file) for file in CSV_HOLDING_FOLDERS]

    if False:
        # do the extraction
        do_feature_extraction_from_multiple_folders(
            csv_holding_folders=CSV_HOLDING_FOLDERS, 
            predictions_path=PREDICTIONS_PATH, 
            clf_sav_path=CLFPATH, 
            computed_feature_saving_path=SAVEPATH,
            feature_loading_path=LOADPATH,
            fps=40, 
            brute_thresholding=False, 
            threshold=0.8, 
            recompute=False, 
            save_result=True, 
            pose=POSE
        )

    ROOT   = r"X:\Raymond Lab\2 Colour D1 D2 Photometry Project\Akira\DLC\Q175\csv\allcsv_2024_06_20_Akira"
    TARGET = r"X:\Raymond Lab\2 Colour D1 D2 Photometry Project\Akira\BSOID\Q175\labeled_features"

    ROOT = convert_to_current_file_drive(ROOT)
    TARGET = convert_to_current_file_drive(TARGET)
    
    if True:
        # given a folder holding csvs into a set directory structure, copy
        # over any corresponding labeled feature into another directory
        # while handling any computation that is needed
        extract_labeled_csv_through_walk(
            root=ROOT,
            target=TARGET,
            predictions_path=PREDICTIONS_PATH,
            clf_sav_path=CLFPATH,
            computed_feature_saving_path=SAVEPATH,
            feature_loading_path=LOADPATH,
            fps=40,
            brute_thresholding=False, 
            threshold=0.8,       
            recompute=False,
            save_result=True,
            pose=POSE
            )